name: Update CSV with PDF files

on:
  push:
    paths:
      - '**/*.pdf'  # Trigger only when PDF files are changed
  workflow_dispatch:  # Allows the workflow to be triggered manually

jobs:
  updateCSV:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: |
          npm install pdf-parse

      - name: Update CSV data
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            const crypto = require('crypto');
            const pdf = require('pdf-parse');

            // Function to generate unique ID
            function generate_id(file_path) {
              return crypto.createHash('md5').update(file_path).digest('hex');
            }

            // Function to get file size in bytes
            function getFileSize(filePath) {
              const stats = fs.statSync(filePath);
              return stats.size;
            }

            // Function to get last modified date
            function getLastModified(filePath) {
              const stats = fs.statSync(filePath);
              return stats.mtime.toISOString();
            }

            // Function to extract PDF metadata
            async function extractPdfMetadata(pdfPath) {
              try {
                const dataBuffer = fs.readFileSync(pdfPath);
                const data = await pdf(dataBuffer);
                return {
                  title: data.info.Title || path.basename(pdfPath, '.pdf'),
                  subject: data.info.Subject || 'No subject available',
                  author: data.info.Author || 'Unknown',
                  creationDate: data.info.CreationDate || 'Unknown'
                };
              } catch (error) {
                console.error(`Error reading PDF metadata for ${pdfPath}: ${error.message}`);
                return {
                  title: path.basename(pdfPath, '.pdf'),
                  subject: 'Error reading metadata',
                  author: 'Unknown',
                  creationDate: 'Unknown'
                };
              }
            }

            const csvFilePath = 'csv_data.csv';
            const pdfFiles = [];
            const delimiter = ';';
            const csvHeader = 'ID;File Path;Title;Subject;Author;Creation Date;Size (bytes);Last Modified;PDF URL;Image URL\n';

            // Collect PDF files from the repository, including subfolders
            const walkSync = (dir, fileList) => {
              const files = fs.readdirSync(dir);
              files.forEach(file => {
                const fullPath = path.join(dir, file);
                if (fs.statSync(fullPath).isDirectory()) {
                  if (!file.startsWith('.') && file !== 'node_modules') {
                    fileList = walkSync(fullPath, fileList);
                  }
                } else {
                  if (file.toLowerCase().endsWith('.pdf')) {
                    fileList.push(fullPath);
                  }
                }
              });
              return fileList;
            };

            // Read existing CSV data if it exists
            let existingEntries = new Map();
            if (fs.existsSync(csvFilePath)) {
              const existingData = fs.readFileSync(csvFilePath, 'utf-8').split('\n');
              // Remove header and empty lines
              existingData.slice(1).filter(line => line.trim()).forEach(line => {
                const fields = line.split(delimiter);
                if (fields.length >= 9) {
                  // Preserve existing image URL if it exists
                  existingEntries.set(fields[0], fields[9] || '');
                }
              });
            }

            const allPdfFiles = walkSync('.', pdfFiles);
            let csvData = csvHeader;

            // Process all PDF files
            await Promise.all(allPdfFiles.map(async (pdfPath) => {
              const id = generate_id(pdfPath);
              const metadata = await extractPdfMetadata(pdfPath);
              const size = getFileSize(pdfPath);
              const lastModified = getLastModified(pdfPath);
              const pdfUrl = `https://raw.githubusercontent.com/${process.env.GITHUB_REPOSITORY}/main/${pdfPath}`;
              const imageUrl = existingEntries.get(id) || ''; // Preserve existing image URL

              // Add entry to CSV
              csvData += `${id};${pdfPath};${metadata.title};${metadata.subject};${metadata.author};${metadata.creationDate};${size};${lastModified};${pdfUrl};${imageUrl}\n`;
            }));

            // Write the CSV data to the file
            fs.writeFileSync(csvFilePath, csvData);

      - name: Commit changes
        env:
          ACTIONS_PAT: ${{ secrets.ACTIONS_PAT }}
        run: |
          git config --local user.email "actions@github.com"
          git config --local user.name "GitHub Actions Bot"
          git add csv_data.csv
          git commit -m "csv_data.csv updated with PDF metadata" || echo "No changes to commit"
          git push "https://x-access-token:${{ secrets.ACTIONS_PAT }}@github.com/${{ github.repository }}.git"
