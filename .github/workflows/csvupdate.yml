name: Update CSV File

on:
  push:
    paths:
      - '**/*.pdf'  # Trigger only when a PDF file is added or modified

jobs:
  csv-update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout main branch
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v2

      - name: Install dependencies
        run: |
          pip install pandas

      - name: Update CSV file
        env:
          GITHUB_TOKEN: ${{ secrets.ACTIONS_PAT }}  # Ensure you have set this secret in your repository
        run: |
          python - <<EOF
import os
import pandas as pd
from datetime import datetime
import hashlib

# Function to generate a unique ID for each PDF
def generate_id(file_path):
    return hashlib.md5(file_path.encode()).hexdigest()

# Function to extract metadata (placeholder implementation)
def extract_metadata(file_path):
    # Replace this with actual metadata extraction logic
    return {
        'title': os.path.basename(file_path),
        'categories': 'Uncategorized',
        'description': f'Report file located at {file_path}',
        'creation_date': datetime.now().strftime('%Y-%m-%d'),
        'upload_date': datetime.now().strftime('%Y-%m-%d'),
        'report_year': datetime.now().year,
        'report_quarter': (datetime.now().month - 1) // 3 + 1,
        'image_url': '',
    }

# Find all PDF files in the repository
pdf_files = []
for root, _, files in os.walk('.'):
    for file in files:
        if file.endswith(".pdf"):
            pdf_files.append(os.path.join(root, file))


# Load existing CSV data
csv_file_path = 'data/stats.csv'
if os.path.exists(csv_file_path):
    existing_data = pd.read_csv(csv_file_path)
else:
    existing_data = pd.DataFrame(columns=[
        'ID', 'Title', 'Categories', 'Description', 'Creation Date', 'Upload Date',
        'Report Year', 'Report Quarter', 'Image URL', 'PDF URL'
    ])

# Update the CSV data
for pdf_file in pdf_files:
    pdf_url = pdf_file[2:].replace('\\', '/')
    if not existing_data[existing_data['PDF URL'] == pdf_url].empty:
        continue

    metadata = extract_metadata(pdf_file)
    new_entry = {
        'ID': generate_id(pdf_url),
        'Title': metadata['title'],
        'Categories': metadata['categories'],
        'Description': metadata['description'],
        'Creation Date': metadata['creation_date'],
        'Upload Date': metadata['upload_date'],
        'Report Year': metadata['report_year'],
        'Report Quarter': metadata['report_quarter'],
        'Image URL': metadata['image_url'],
        'PDF URL': pdf_url,
    }
    existing_data = existing_data.append(new_entry, ignore_index=True)

# Save the updated CSV data
existing_data.to_csv(csv_file_path, index=False)
EOF

      - name: Commit changes
        env:
          GITHUB_TOKEN: ${{ secrets.ACTIONS_PAT }}  # Use the PAT for committing changes
        run: |
          git config --global user.name 'github-actions'
          git config --global user.email 'github-actions@github.com'
          git add csv_data.csv
          git commit -m "Update CSV file with new PDF metadata" || echo "No changes to commit"
          git push
